{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55e64f44-dbbb-4cf6-9795-cd6bf9c8acdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/homes/a/achen899/.conda/envs/env_gan/lib/python3.9/site-packages/nvidia/cudnn/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import nvidia.cudnn\n",
    "print(nvidia.cudnn.__file__)\n",
    "sys.path.append('/global/homes/a/achen899/.local/perlmutter/3.9-anaconda-2021.11/lib/python3.9/site-packages/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcc5704-381d-4ea6-99a7-734fc026c25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-11 13:44:13.217769: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-11 13:44:19.489271: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True000\n"
     ]
    }
   ],
   "source": [
    "from hadronic_to_root import convert\n",
    "import pprint\n",
    "import awkward as ak\n",
    "import uproot\n",
    "\n",
    "convert(\"/global/cfs/projectdirs/m3443/data/ForHadronic/train_data/hadron_pi_mode2.csv\", \"/global/cfs/projectdirs/m3443/data/ForHadronic/train_data/pimode/hadron_pi_mode.root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3fb769-552c-41b2-aa61-7076d99e5e75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000\n",
      "3000000\n"
     ]
    }
   ],
   "source": [
    "import uproot\n",
    "\n",
    "out_branch_names = ['particle_id', \"particle_E\", \"particle_px\", \"particle_py\", \"particle_pz\"]\n",
    "in_branch_names = ['incoming']\n",
    "branch_names = out_branch_names + in_branch_names\n",
    "\n",
    "f = uproot.open(\"/global/cfs/projectdirs/m3443/data/ForHadronic/train_data/pimode/hadron_pi_mode.root\")\n",
    "tree = f[\"output\"]\n",
    "all_dict = tree.arrays(branch_names, library=\"np\")\n",
    "  \n",
    "print(len(all_dict['incoming']))\n",
    "print(len(all_dict['particle_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6392769f-1531-4e8b-b8e2-e6322248bb72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1634977, 5)\n",
      "(1634977, 5)\n"
     ]
    }
   ],
   "source": [
    "#import pypdt\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "cond_vectors, truth_vectors = np.zeros(5), np.zeros(5)\n",
    "\n",
    "scale_max = 0\n",
    "scale_min = 0\n",
    "particle_type_count = 1\n",
    "partdict = dict()\n",
    "count=1\n",
    "for i, cond in enumerate(df[\"incoming\"]):\n",
    "    remaining_in_vector = cond\n",
    "    scale_max = max(scale_max, cond[0])\n",
    "    for j, o_energy in enumerate(df[\"particle_E\"][i]):\n",
    "        if df[\"particle_id\"][i][j] in partdict.keys():\n",
    "            truth_vector = np.array([o_energy, df[\"particle_px\"][i][j], df[\"particle_py\"][i][j], df[\"particle_pz\"][i][j], partdict[df[\"particle_id\"][i][j]]])\n",
    "        else:\n",
    "            partdict[df[\"particle_id\"][i][j]] = particle_type_count\n",
    "            truth_vector = np.array([o_energy, df[\"particle_px\"][i][j], df[\"particle_py\"][i][j], df[\"particle_pz\"][i][j], partdict[df[\"particle_id\"][i][j]]])\n",
    "            particle_type_count += 1\n",
    "        #print(truth_vector[4], end =\" \")\n",
    "        cond_vector = np.append(remaining_in_vector, [j])\n",
    "        cond_vectors = np.vstack((cond_vectors, cond_vector))\n",
    "        truth_vectors = np.vstack((truth_vectors, truth_vector))\n",
    "        remaining_in_vector = remaining_in_vector - truth_vector[:4]\n",
    "    scale_min = min(scale_min, remaining_in_vector[0])\n",
    "    print(count, end=\"\\r\", flush=True)\n",
    "    count += 1\n",
    "ecv_i = cond_vectors[1:,4]\n",
    "etv_id = truth_vectors[1:,4]\n",
    "\n",
    "truth_vectors_no_id = truth_vectors[1:,:4]\n",
    "cond_vectors_no_i = cond_vectors[1:,:4]\n",
    "truth_vectors_no_id = pscale(truth_vectors_no_id, scale_max, scale_min)\n",
    "cond_vectors_no_i = pscale(cond_vectors_no_i, scale_max, scale_min)\n",
    "\n",
    "cond_vectors = np.concatenate((cond_vectors_no_i, ecv_i[:, None]), axis=1)\n",
    "truth_vectors = np.concatenate((etv_id[:, None], truth_vectors_no_id), axis=1)\n",
    "\n",
    "print(np.shape(truth_vectors))\n",
    "print(np.shape(cond_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67807a2-aac8-4992-91a4-0285217608f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_gan_g",
   "language": "python",
   "name": "env_gan_g"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
